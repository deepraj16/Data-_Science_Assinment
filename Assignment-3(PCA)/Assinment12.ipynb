{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa0d236-2593-4c7e-9263-335eab52753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support          itemsets\n",
      "0     0.75          (Banana)\n",
      "1     0.75           (Apple)\n",
      "2     0.75          (Orange)\n",
      "3     0.50  (Orange, Banana)\n",
      "4     0.50   (Apple, Banana)\n",
      "5     0.50   (Orange, Apple)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "transactions = [['Apple', 'Banana'], ['Apple', 'Orange'],\n",
    "['Banana', 'Orange'], ['Apple', 'Banana', 'Orange']]\n",
    "# Transaction Encoding\n",
    "te= TransactionEncoder()\n",
    "transformed_data = te.fit(transactions).transform(transactions)\n",
    "df =pd. DataFrame(transformed_data, columns=te.columns_)\n",
    "frequent_itemsets =fpgrowth (df, min_support=0.5, use_colnames=True)\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5728fb1-0002-4603-850a-0faa922d7e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bread</th>\n",
       "      <th>Bun</th>\n",
       "      <th>Tea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bread    Bun    Tea\n",
       "0  False   True   True\n",
       "1   True  False   True\n",
       "2   True   True  False\n",
       "3   True   True   True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q3 =\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "transactions = [['Tea', 'Bun'], ['Tea', 'Bread'], ['Bread', 'Bun'], ['Tea', 'Bun', 'Bread']]\n",
    "\n",
    "te= TransactionEncoder()\n",
    "transformed_data = te.fit(transactions).transform(transactions)\n",
    "df =pd.DataFrame(transformed_data, columns=te.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a6a96a4-4e14-4a41-af2a-80ab19bdf651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(0, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support itemsets\n",
       "0     0.75      (0)\n",
       "1     0.75      (1)\n",
       "2     0.75      (2)\n",
       "3     0.50   (0, 1)\n",
       "4     0.50   (0, 2)\n",
       "5     0.50   (1, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat=apriori(df, min_support=0.3)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225f5177-6b38-4221-8900-ef2062eb3de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(association_rules(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c6425ad-ced2-4f2b-bdcb-93b2502ca490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qusestion \"1-Recomdation system\" \n",
    "df=pd.read_csv('Entertainment.csv.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56741202-e5e5-4815-8273-740e814d347c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Titles</th>\n",
       "      <th>Category</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6973</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Drama, Romance, School, Supernatural</td>\n",
       "      <td>-8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6778</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
       "      <td>8.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9702</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6769</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Sci-Fi, Thriller</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1123</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                              Titles                                           Category  Reviews\n",
       "0  6973                    Toy Story (1995)               Drama, Romance, School, Supernatural    -8.98\n",
       "1  6778                      Jumanji (1995)  Action, Adventure, Drama, Fantasy, Magic, Mili...     8.88\n",
       "2  9702             Grumpier Old Men (1995)  Action, Comedy, Historical, Parody, Samurai, S...    99.00\n",
       "3  6769            Waiting to Exhale (1995)                                   Sci-Fi, Thriller    99.00\n",
       "4  1123  Father of the Bride Part II (1995)  Action, Comedy, Historical, Parody, Samurai, S...    -0.44"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3db22b5f-0b3c-491c-b014-b92e94ec9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a1a353c-c0a3-4dc5-ad64-130946266607",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim=cosine_similarity(df[['Reviews']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d071bc8d-726c-478d-a59b-28fddf40b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomdation(example): \n",
    "    idx=df[df['Titles']==example].index[0]\n",
    "     #get the pairewic simalrty for give matrix  \n",
    "    sim_scores=list(enumerate(cosine_sim[idx]))\n",
    "    #sort the title \n",
    "    sim_scores=sorted(sim_scores,key=lambda x:x[1],reverse=True) \n",
    "    ##get the index the most similarity \n",
    "    sim_indices = [i[0] for i in sim_scores[1:6]]\n",
    "    \n",
    "    return sim_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8cdbcf0-851d-45c3-9df9-aec148484e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Father of the Bride Part II (1995)\n",
      "Heat (1995)\n",
      "Tom and Huck (1995)\n",
      "Sudden Death (1995)\n",
      "Dracula: Dead and Loving It (1995)\n"
     ]
    }
   ],
   "source": [
    "example=\"Toy Story (1995)\" \n",
    "l=recomdation(example)\n",
    "for i in l: \n",
    "    print(df['Titles'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4f86fc6e-e42e-4d78-a6fa-c0aef602070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>Harold and Maude</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Ford v Ferrari</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Anand</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>La dolce vita</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Series_Title  IMDB_Rating\n",
       "541  Harold and Maude          7.9\n",
       "217    Ford v Ferrari          8.1\n",
       "76              Anand          8.4\n",
       "516       Toy Story 2          7.9\n",
       "435     La dolce vita          8.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Qusetion 5\n",
    "df_norm =pd.read_csv(\"imdb_top_1000.csv\")[['Series_Title','IMDB_Rating']]\n",
    "df_norm.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "750864a2-32a9-4b48-93c9-8868a2fdbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "dbscan= DBSCAN(eps=0.05,min_samples=3)\n",
    "k=dbscan.fit_predict(df_norm[['IMDB_Rating']])\n",
    "df_norm['cluster']=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cf146a5e-9992-4cfa-a9df-5d1efab3a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomdation3(example): \n",
    "    idx=df_norm[df_norm['Series_Title']==example].index[0]\n",
    "     #get the pairewic simalrty for give matrix  \n",
    "    l=df_norm['cluster'].iloc[idx]\n",
    "    df_norm[df_norm['cluster']==l].head(2)\n",
    "    li=list(df_norm[df_norm['cluster']==14 ]['Series_Title'].head(5))\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6eb879f8-f05d-4352-82d8-80a66c73a2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dark Waters',\n",
       " 'Searching',\n",
       " 'Once Upon a Time... in Hollywood',\n",
       " 'Nelyubov',\n",
       " 'The Florida Project']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=\"The Nightmare Before Christmas\" \n",
    "l=recomdation3(example)\n",
    "# for i in l: \n",
    "#     print(df['Titles'].iloc[i])\n",
    "list(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ccf566de-15bc-43d3-83aa-37a46fac4ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=df_norm[df_norm['Series_Title']==example].index[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "389f70b4-7eaf-48c7-b92f-2f6196165b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=df_norm['cluster'].iloc[idx]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c0ef96f-6d35-4bf3-a018-0849affa6688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2127027e-df9f-4df9-b2ad-6867d9d3aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My 3rd time watching this movie! Yet, it still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to keep my review rather to the point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You only get to watch this for the first time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When you wake up from a good dream, you feel t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 20th Century had Casablanca, Star Wars, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text\n",
       "0  My 3rd time watching this movie! Yet, it still...\n",
       "1  I'd like to keep my review rather to the point...\n",
       "2  You only get to watch this for the first time ...\n",
       "3  When you wake up from a good dream, you feel t...\n",
       "4  The 20th Century had Casablanca, Star Wars, th..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new= pd.read_csv(\"IMDb_Movie_Reviews.csv\")\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cf21db3-27f0-4dbd-9919-d20538a51de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " '3rd',\n",
       " 'time',\n",
       " 'watching',\n",
       " 'this',\n",
       " 'movie!',\n",
       " 'Yet,',\n",
       " 'it',\n",
       " 'still',\n",
       " 'stunned',\n",
       " 'my',\n",
       " 'mind,',\n",
       " 'kept',\n",
       " 'me',\n",
       " 'enjoyed',\n",
       " 'its',\n",
       " 'every',\n",
       " 'moment',\n",
       " 'and',\n",
       " 'left',\n",
       " 'me',\n",
       " 'with',\n",
       " 'many',\n",
       " 'thoughts',\n",
       " 'afterward.For',\n",
       " 'someone',\n",
       " 'like',\n",
       " 'me,',\n",
       " \"who've\",\n",
       " 'rarely',\n",
       " 'slept',\n",
       " 'without',\n",
       " 'dream,',\n",
       " \"it's\",\n",
       " 'so',\n",
       " 'exciting',\n",
       " 'watching',\n",
       " 'how',\n",
       " 'Christopher',\n",
       " 'Nolan',\n",
       " 'had',\n",
       " 'illustrated',\n",
       " 'every',\n",
       " 'single',\n",
       " 'characteristic',\n",
       " 'of',\n",
       " 'dream',\n",
       " 'on',\n",
       " 'the',\n",
       " 'big',\n",
       " 'screen.',\n",
       " 'As',\n",
       " \"it's\",\n",
       " 'been',\n",
       " 'done',\n",
       " 'so',\n",
       " 'sophisticatedly,',\n",
       " 'I',\n",
       " 'do',\n",
       " 'believe',\n",
       " 'the',\n",
       " 'rumour',\n",
       " 'that',\n",
       " 'Nolan',\n",
       " 'had',\n",
       " 'spent',\n",
       " '10',\n",
       " 'years',\n",
       " 'to',\n",
       " 'finish',\n",
       " 'the',\n",
       " 'script',\n",
       " 'of',\n",
       " 'Inception.',\n",
       " 'In',\n",
       " 'my',\n",
       " 'opinion,',\n",
       " \"it's\",\n",
       " 'been',\n",
       " 'so',\n",
       " 'far',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'achievement',\n",
       " 'in',\n",
       " 'his',\n",
       " 'brilliant',\n",
       " 'writer-director',\n",
       " 'career.',\n",
       " 'I',\n",
       " 'jumped',\n",
       " 'into',\n",
       " 'this',\n",
       " 'conclusion',\n",
       " 'after',\n",
       " 'making',\n",
       " 'a',\n",
       " 'quick',\n",
       " 'benchmark',\n",
       " 'of',\n",
       " \"Nolan's\",\n",
       " 'remarkable',\n",
       " 'works:\\nMemento,',\n",
       " 'as',\n",
       " 'his',\n",
       " 'first',\n",
       " 'signature',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cinema',\n",
       " 'history,',\n",
       " 'is',\n",
       " 'tremendous',\n",
       " 'and',\n",
       " 'has',\n",
       " 'stayed',\n",
       " 'the',\n",
       " 'most',\n",
       " 'mind-bending',\n",
       " 'film',\n",
       " \"I've\",\n",
       " 'ever',\n",
       " 'seen.',\n",
       " 'But',\n",
       " 'overall,',\n",
       " 'it',\n",
       " \"doesn't\",\n",
       " 'reach',\n",
       " 'the',\n",
       " 'same',\n",
       " 'level',\n",
       " 'of',\n",
       " 'Inception.The',\n",
       " 'Prestige',\n",
       " 'is',\n",
       " 'highly',\n",
       " 'impressive',\n",
       " 'but',\n",
       " 'somehow',\n",
       " 'I',\n",
       " \"haven't\",\n",
       " 'been',\n",
       " 'able',\n",
       " 'to',\n",
       " 'find',\n",
       " 'the',\n",
       " 'very',\n",
       " 'particular',\n",
       " '\"Nolan\\'s',\n",
       " 'spirit\"',\n",
       " 'in',\n",
       " 'it.The',\n",
       " 'Batman',\n",
       " 'Trilogy',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'superhero',\n",
       " 'saga',\n",
       " 'of',\n",
       " 'all',\n",
       " 'time',\n",
       " 'and',\n",
       " 'its',\n",
       " 'peak',\n",
       " 'The',\n",
       " 'Dark',\n",
       " 'Knight',\n",
       " 'is',\n",
       " 'no',\n",
       " 'doubt',\n",
       " 'a',\n",
       " 'masterpiece',\n",
       " 'as',\n",
       " 'well.',\n",
       " 'Nonetheless,',\n",
       " 'every',\n",
       " 'time',\n",
       " 'we',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'it,',\n",
       " 'Heath',\n",
       " 'Ledger',\n",
       " 'takes',\n",
       " 'all',\n",
       " 'the',\n",
       " 'spotlights',\n",
       " 'with',\n",
       " 'his',\n",
       " 'life-time-role:',\n",
       " 'The',\n",
       " '(unique-and-only)',\n",
       " 'Joker.Then',\n",
       " 'there',\n",
       " 'came',\n",
       " 'Inception',\n",
       " 'where',\n",
       " 'Nolan',\n",
       " 'truly',\n",
       " 'stood',\n",
       " 'out,',\n",
       " 'having',\n",
       " 'every',\n",
       " 'single',\n",
       " 'detail',\n",
       " 'of',\n",
       " 'his',\n",
       " 'work',\n",
       " 'done',\n",
       " 'in',\n",
       " 'the',\n",
       " 'finest',\n",
       " 'way.',\n",
       " 'The',\n",
       " 'multi-layered',\n",
       " 'storyline',\n",
       " 'despite',\n",
       " 'its',\n",
       " 'complexity,',\n",
       " 'remains',\n",
       " 'consistent',\n",
       " 'and',\n",
       " 'originally',\n",
       " 'interesting.',\n",
       " 'From',\n",
       " 'visual',\n",
       " 'aspect,',\n",
       " 'everything',\n",
       " 'was',\n",
       " 'masterly',\n",
       " 'handled:',\n",
       " 'an',\n",
       " 'impeccable',\n",
       " 'cross-cutting',\n",
       " 'allowed',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'to',\n",
       " 'follow',\n",
       " \"Nolan's\",\n",
       " 'nonlinear',\n",
       " 'story-telling',\n",
       " 'without',\n",
       " 'being',\n",
       " 'scattered;',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'cinematography',\n",
       " 'work',\n",
       " 'completed',\n",
       " 'with',\n",
       " 'incredibly',\n",
       " 'imaginative',\n",
       " 'visual-effects',\n",
       " 'brought',\n",
       " 'into',\n",
       " 'life',\n",
       " 'so',\n",
       " 'many',\n",
       " 'breathtaking',\n",
       " 'scenes,',\n",
       " 'some',\n",
       " 'of',\n",
       " 'them,',\n",
       " 'I',\n",
       " 'believe,',\n",
       " 'will',\n",
       " 'stay',\n",
       " 'in',\n",
       " 'the',\n",
       " \"audience's\",\n",
       " 'mind',\n",
       " 'for',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time',\n",
       " '(city',\n",
       " 'bending',\n",
       " 'in',\n",
       " 'Paris,',\n",
       " 'zero-gravity',\n",
       " 'fight,',\n",
       " 'in',\n",
       " 'limbo,',\n",
       " 'dreams',\n",
       " 'collapsing...).',\n",
       " 'In',\n",
       " 'addition,',\n",
       " 'Nolan',\n",
       " 'had',\n",
       " 'also',\n",
       " 'a',\n",
       " 'solid',\n",
       " 'cast',\n",
       " 'ensemble',\n",
       " 'to',\n",
       " 'help',\n",
       " 'him',\n",
       " 'deliver',\n",
       " 'all',\n",
       " 'of',\n",
       " 'his',\n",
       " 'messages.Later,',\n",
       " 'we',\n",
       " 'had',\n",
       " 'Interstellar.',\n",
       " 'Though',\n",
       " 'I',\n",
       " 'did',\n",
       " 'admire',\n",
       " 'its',\n",
       " 'cinematography',\n",
       " 'and',\n",
       " 'visual-effects,',\n",
       " 'the',\n",
       " 'film',\n",
       " 'itself',\n",
       " 'is',\n",
       " 'nowhere',\n",
       " 'near',\n",
       " 'the',\n",
       " 'level',\n",
       " 'of',\n",
       " 'Inception.\\nSPOILERS',\n",
       " 'AHEAD',\n",
       " '!!!!!',\n",
       " 'For',\n",
       " 'all',\n",
       " 'who',\n",
       " \"haven't\",\n",
       " 'watched',\n",
       " 'this',\n",
       " 'movie,',\n",
       " 'you',\n",
       " 'may',\n",
       " 'stop',\n",
       " 'the',\n",
       " 'reading',\n",
       " 'right',\n",
       " 'here',\n",
       " 'because',\n",
       " 'the',\n",
       " 'following',\n",
       " 'paragraphs',\n",
       " 'contain',\n",
       " 'a',\n",
       " 'ton',\n",
       " 'of',\n",
       " 'spoilers!It',\n",
       " 'is',\n",
       " 'set',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'where',\n",
       " \"there's\",\n",
       " 'technology',\n",
       " 'that',\n",
       " 'allows',\n",
       " 'people',\n",
       " 'to',\n",
       " 'literally',\n",
       " 'share',\n",
       " 'dream.',\n",
       " 'There',\n",
       " 'is,',\n",
       " 'in',\n",
       " 'this',\n",
       " 'world,',\n",
       " 'a',\n",
       " 'new',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'corporate',\n",
       " 'spy',\n",
       " '-',\n",
       " '\"extractors\"',\n",
       " 'who',\n",
       " 'use',\n",
       " 'this',\n",
       " 'technology',\n",
       " 'to',\n",
       " 'infiltrate',\n",
       " 'the',\n",
       " \"target's\",\n",
       " 'subconscious',\n",
       " 'and',\n",
       " 'extract',\n",
       " 'valuable',\n",
       " 'information',\n",
       " 'through',\n",
       " 'a',\n",
       " 'shared',\n",
       " 'dream',\n",
       " 'world.',\n",
       " 'Our',\n",
       " 'hero',\n",
       " 'Mr',\n",
       " 'Cobb',\n",
       " '(Leonardo',\n",
       " 'DiCaprio),',\n",
       " 'a',\n",
       " 'very',\n",
       " 'well-known',\n",
       " 'extractor,',\n",
       " 'and',\n",
       " 'his',\n",
       " 'partner',\n",
       " 'Arthur',\n",
       " '(Joseph',\n",
       " 'Gordon-Levitt)',\n",
       " 'are',\n",
       " 'approached',\n",
       " 'by',\n",
       " 'a',\n",
       " 'powerful',\n",
       " 'businessman',\n",
       " '-',\n",
       " 'Mr',\n",
       " 'Saito',\n",
       " '(Ken',\n",
       " 'Watanabe)',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nearly',\n",
       " 'impossible',\n",
       " 'mission,',\n",
       " 'something',\n",
       " 'no',\n",
       " 'one',\n",
       " 'has',\n",
       " 'ever',\n",
       " 'done',\n",
       " 'before',\n",
       " ':',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'stealing,',\n",
       " 'he',\n",
       " 'wants',\n",
       " 'them',\n",
       " 'to',\n",
       " 'plant',\n",
       " 'an',\n",
       " 'idea',\n",
       " 'in',\n",
       " 'a',\n",
       " \"person's\",\n",
       " 'subconscious,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'also',\n",
       " 'called',\n",
       " '\"inception\".',\n",
       " 'In',\n",
       " 'return,',\n",
       " 'Saito',\n",
       " 'offers',\n",
       " 'something',\n",
       " 'that',\n",
       " 'Cobb',\n",
       " 'could',\n",
       " 'never',\n",
       " 'resist:',\n",
       " 'a',\n",
       " 'ticket',\n",
       " 'to',\n",
       " 'go',\n",
       " 'home',\n",
       " 'with',\n",
       " 'his',\n",
       " 'children',\n",
       " 'by',\n",
       " 'taking',\n",
       " 'out',\n",
       " 'the',\n",
       " 'homicide',\n",
       " 'charge',\n",
       " 'against',\n",
       " 'him.',\n",
       " 'So',\n",
       " 'Cobb',\n",
       " 'and',\n",
       " 'Arthur',\n",
       " 'gather',\n",
       " 'a',\n",
       " 'team',\n",
       " 'to',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'the',\n",
       " 'mission:',\n",
       " 'Eames',\n",
       " '(Tom',\n",
       " 'Hardy)',\n",
       " '-',\n",
       " 'a',\n",
       " 'veteran',\n",
       " 'identity',\n",
       " 'forger,',\n",
       " 'Yusuf',\n",
       " '-',\n",
       " 'the',\n",
       " 'only',\n",
       " 'one',\n",
       " 'chemist',\n",
       " 'can',\n",
       " 'make',\n",
       " 'such',\n",
       " 'a',\n",
       " 'powerful',\n",
       " 'sedative',\n",
       " 'for',\n",
       " 'such',\n",
       " 'a',\n",
       " 'complex',\n",
       " '3-levels',\n",
       " '\"dream',\n",
       " 'within',\n",
       " 'a',\n",
       " 'dream\",',\n",
       " 'and',\n",
       " 'Ariadne',\n",
       " '(Ellen',\n",
       " 'Page)',\n",
       " '-',\n",
       " 'a',\n",
       " 'newbie',\n",
       " 'but',\n",
       " 'remarkably',\n",
       " 'talented',\n",
       " 'architect',\n",
       " 'whose',\n",
       " 'role',\n",
       " 'is',\n",
       " 'critical',\n",
       " 'for',\n",
       " 'the',\n",
       " 'success',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mission.',\n",
       " 'The',\n",
       " 'target',\n",
       " 'is',\n",
       " 'Robert',\n",
       " 'Fischer',\n",
       " '(Cillian',\n",
       " 'Murphy)',\n",
       " '-',\n",
       " 'son',\n",
       " 'and',\n",
       " 'heir',\n",
       " 'of',\n",
       " \"Saito's\",\n",
       " 'biggest',\n",
       " 'competitor',\n",
       " '(Maurice',\n",
       " 'Fischer,',\n",
       " \"who's\",\n",
       " 'dying).',\n",
       " 'The',\n",
       " 'goal',\n",
       " 'is',\n",
       " 'to',\n",
       " 'seed',\n",
       " 'an',\n",
       " 'idea',\n",
       " 'into',\n",
       " 'his',\n",
       " 'mind',\n",
       " 'which',\n",
       " 'will',\n",
       " 'make',\n",
       " 'him',\n",
       " 'abandon',\n",
       " 'his',\n",
       " \"father's\",\n",
       " 'business,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'team',\n",
       " 'has',\n",
       " 'to',\n",
       " 'carry',\n",
       " 'Saito',\n",
       " 'as',\n",
       " 'visitor',\n",
       " 'in',\n",
       " 'their',\n",
       " 'mission',\n",
       " 'to',\n",
       " 'let',\n",
       " 'him',\n",
       " 'verify',\n",
       " 'the',\n",
       " 'result',\n",
       " 'of',\n",
       " 'inception.',\n",
       " 'While',\n",
       " 'the',\n",
       " 'team',\n",
       " 'go',\n",
       " 'deeper',\n",
       " 'and',\n",
       " 'deeper',\n",
       " 'into',\n",
       " \"Fischer's\",\n",
       " 'mind,',\n",
       " 'we',\n",
       " 'discover',\n",
       " 'gradually',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'of',\n",
       " \"Cobb's\",\n",
       " 'past,',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " '2',\n",
       " 'biggest',\n",
       " 'why',\n",
       " 'concerning',\n",
       " 'our',\n",
       " 'hero:',\n",
       " 'Why',\n",
       " 'he',\n",
       " 'has',\n",
       " 'became',\n",
       " 'such',\n",
       " 'an',\n",
       " 'expert',\n",
       " 'of',\n",
       " 'inception',\n",
       " 'and',\n",
       " 'What',\n",
       " 'is',\n",
       " 'his',\n",
       " 'desperate',\n",
       " 'motivation',\n",
       " 'for',\n",
       " 'taking',\n",
       " 'that',\n",
       " 'insane',\n",
       " 'mission.The',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'not',\n",
       " 'only',\n",
       " 'about',\n",
       " 'the',\n",
       " 'inception',\n",
       " 'mission',\n",
       " 'but',\n",
       " 'more',\n",
       " 'importantly,',\n",
       " 'about',\n",
       " 'the',\n",
       " 'struggle',\n",
       " 'of',\n",
       " 'finding',\n",
       " 'the',\n",
       " 'way',\n",
       " 'in',\n",
       " 'the',\n",
       " 'maze',\n",
       " 'of',\n",
       " 'life.',\n",
       " 'In',\n",
       " \"Cobb's\",\n",
       " 'case,',\n",
       " \"it's\",\n",
       " 'the',\n",
       " 'maze',\n",
       " 'of',\n",
       " 'dreams',\n",
       " 'built',\n",
       " 'by',\n",
       " 'his',\n",
       " 'memories',\n",
       " 'with',\n",
       " 'his',\n",
       " 'past',\n",
       " 'wife',\n",
       " 'Mal',\n",
       " '(Marion',\n",
       " 'Cotillard)',\n",
       " 'and',\n",
       " 'his',\n",
       " 'regrets.',\n",
       " 'So',\n",
       " 'as',\n",
       " 'long',\n",
       " 'as',\n",
       " 'he',\n",
       " 'let',\n",
       " 'himself',\n",
       " 'consumed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'past',\n",
       " 'by',\n",
       " 'blaming',\n",
       " 'himself',\n",
       " 'for',\n",
       " 'the',\n",
       " 'death',\n",
       " 'of',\n",
       " 'his',\n",
       " 'love',\n",
       " 'wife,',\n",
       " 'it',\n",
       " 'will',\n",
       " 'keep',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'and',\n",
       " 'haunt',\n",
       " 'his',\n",
       " 'present:',\n",
       " 'the',\n",
       " 'deeper',\n",
       " 'the',\n",
       " 'team',\n",
       " 'go',\n",
       " 'into',\n",
       " 'dream,',\n",
       " 'the',\n",
       " 'more',\n",
       " 'dangerous',\n",
       " 'his',\n",
       " 'subconscious,',\n",
       " 'under',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'his',\n",
       " 'ghostly',\n",
       " 'wife,',\n",
       " 'comes',\n",
       " 'out',\n",
       " 'and',\n",
       " 'could',\n",
       " 'anytime',\n",
       " 'jeopardize',\n",
       " 'the',\n",
       " 'mission.',\n",
       " 'Indeed,',\n",
       " 'if',\n",
       " 'we',\n",
       " 'apprehend',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'with',\n",
       " 'these',\n",
       " '2',\n",
       " 'layers',\n",
       " 'of',\n",
       " 'its',\n",
       " 'story,',\n",
       " 'the',\n",
       " 'ending',\n",
       " 'scene',\n",
       " 'makes',\n",
       " 'perfect',\n",
       " 'sense.',\n",
       " 'Yes!',\n",
       " \"We're\",\n",
       " 'now',\n",
       " 'talking',\n",
       " 'about',\n",
       " 'that',\n",
       " 'famous',\n",
       " 'ending',\n",
       " 'which',\n",
       " 'has',\n",
       " 'still',\n",
       " 'remained',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'controversial',\n",
       " 'movie',\n",
       " 'endings',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cinema',\n",
       " 'history.',\n",
       " 'Did',\n",
       " 'Cobb',\n",
       " 'find',\n",
       " 'Mr',\n",
       " 'Saito',\n",
       " 'in',\n",
       " 'limbo,',\n",
       " 'bring',\n",
       " 'he',\n",
       " 'back',\n",
       " 'to',\n",
       " 'complete',\n",
       " 'the',\n",
       " 'mission',\n",
       " 'then',\n",
       " 'come',\n",
       " 'back',\n",
       " 'to',\n",
       " 'his',\n",
       " 'children',\n",
       " 'in',\n",
       " 'the',\n",
       " 'real',\n",
       " 'world?',\n",
       " 'Or',\n",
       " 'they',\n",
       " 'are',\n",
       " 'still',\n",
       " 'stuck',\n",
       " 'in',\n",
       " 'limbo',\n",
       " '-',\n",
       " 'the',\n",
       " 'infinite',\n",
       " 'dream',\n",
       " 'world,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'last',\n",
       " 'scene',\n",
       " 'was',\n",
       " 'just',\n",
       " 'his',\n",
       " 'big',\n",
       " 'dream?',\n",
       " 'But',\n",
       " 'all',\n",
       " 'of',\n",
       " 'those',\n",
       " 'question',\n",
       " 'only',\n",
       " 'matter',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'layer',\n",
       " 'of',\n",
       " 'the',\n",
       " 'story:',\n",
       " 'the',\n",
       " 'result',\n",
       " 'of',\n",
       " 'inception',\n",
       " 'mission.',\n",
       " 'When',\n",
       " 'we',\n",
       " 'perceive',\n",
       " 'the',\n",
       " 'story',\n",
       " 'in',\n",
       " 'its',\n",
       " 'deeper',\n",
       " 'layer,',\n",
       " 'as',\n",
       " 'a',\n",
       " 'journey',\n",
       " 'for',\n",
       " 'Cobb',\n",
       " 'to',\n",
       " 'let',\n",
       " 'go',\n",
       " 'of',\n",
       " 'his',\n",
       " 'feeling',\n",
       " 'of',\n",
       " 'guilt',\n",
       " 'for',\n",
       " 'the',\n",
       " 'past',\n",
       " 'and',\n",
       " 're-find',\n",
       " 'the',\n",
       " 'meaning',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life,',\n",
       " 'this',\n",
       " 'ending',\n",
       " 'did',\n",
       " 'fulfill',\n",
       " 'its',\n",
       " 'job.',\n",
       " 'Cobb',\n",
       " \"didn't\",\n",
       " 'even',\n",
       " 'stay',\n",
       " 'to',\n",
       " 'see',\n",
       " 'either',\n",
       " 'if',\n",
       " 'the',\n",
       " 'spinning',\n",
       " 'top',\n",
       " 'would',\n",
       " 'fall',\n",
       " 'because',\n",
       " 'he',\n",
       " \"didn't\",\n",
       " 'care',\n",
       " 'any',\n",
       " 'more,',\n",
       " \"what's\",\n",
       " 'important',\n",
       " 'to',\n",
       " 'him',\n",
       " 'is',\n",
       " 'that',\n",
       " 'he',\n",
       " 'gonna',\n",
       " 'be',\n",
       " 'with',\n",
       " 'his',\n",
       " 'kids.',\n",
       " 'He',\n",
       " 'did',\n",
       " 'finally',\n",
       " 'get',\n",
       " 'rid',\n",
       " 'of',\n",
       " 'his',\n",
       " 'haunting',\n",
       " 'past',\n",
       " 'and',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'move',\n",
       " 'on,',\n",
       " 'and',\n",
       " 'that',\n",
       " 'matters.',\n",
       " 'And',\n",
       " 'after',\n",
       " 'all,',\n",
       " 'dream',\n",
       " 'or',\n",
       " 'reality,',\n",
       " 'the',\n",
       " 'importance',\n",
       " 'is',\n",
       " 'to',\n",
       " 'truly',\n",
       " 'live.',\n",
       " 'So',\n",
       " 'from',\n",
       " 'this',\n",
       " 'point',\n",
       " 'of',\n",
       " 'view,',\n",
       " 'he',\n",
       " 'has',\n",
       " 'solved',\n",
       " 'the',\n",
       " 'maze',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life.\\nSome',\n",
       " 'short',\n",
       " 'lines',\n",
       " 'about',\n",
       " 'the',\n",
       " 'cast:\\nLeo',\n",
       " 'has',\n",
       " 'done',\n",
       " 'justice',\n",
       " 'to',\n",
       " 'our',\n",
       " 'main',\n",
       " 'character',\n",
       " 'but',\n",
       " 'he',\n",
       " 'did',\n",
       " 'not',\n",
       " 'success',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'leap',\n",
       " 'from',\n",
       " 'his',\n",
       " 'previous',\n",
       " 'similar',\n",
       " 'roles',\n",
       " 'in',\n",
       " 'Shutter',\n",
       " 'Island',\n",
       " 'and',\n",
       " 'Blood',\n",
       " ...]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Review_Text'].iloc[0].split(\" \")\n",
    "from nltk.stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "960cc3a4-c254-4659-bf69-b5daf8422353",
   "metadata": {},
   "outputs": [],
   "source": [
    "te =TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ffa9749-a526-4b7c-b8c5-0d5e0aa3a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=te.fit_transform(df_new['Review_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45e718fb-7729-477b-8d86-3152a229d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "l=np.array(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1939b2ae-7d39-4068-af48-de0c1b2ae676",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'csr_matrix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cosine_similarity(l)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m \n\u001b[0;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:175\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[0;32m    172\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype_float\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    176\u001b[0m         X,\n\u001b[0;32m    177\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    178\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    179\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    180\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    181\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    182\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    186\u001b[0m         X,\n\u001b[0;32m    187\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    193\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "cosine_similarity(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268454ee-2760-4d5b-878f-2d820086a0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
